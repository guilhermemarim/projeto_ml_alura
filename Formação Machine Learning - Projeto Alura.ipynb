{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Coloque um cabeçalho nesse notebook com o seu nome e resumindo o que descobriu ao explorar esses dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formação Machine Learning Alura - Dados do ENEM\n",
    "\n",
    "Na formação de Machine Learning da www.alura.com.br vamos inicialmente analisar os dados do Enem 2017. O Enem é uma prova aplicada aos alunos que completam o ensino médio, usada como porta de entrada para diversas faculdades no Brasil. A prova é composta de 9 avaliações distintas: Ciências da Natureza, Ciências Humanas, Linguagens e Códigos, Matemática e 5 competências ligadas a prova de redação.\n",
    "\n",
    "Duas situações podem ser interessantes:\n",
    "\n",
    "a) uma faculdade deseja dar bolsa de estudos para os e as melhores estudantes. Para isso não deseja exigir que as pessoas façam todas as partes da prova.\n",
    "b) seria possível prever a nota dos alunos e alunas se eles fizerem somente parte da prova? Seja deixando em branco propositalmente parte dela, ou exigindo somente uma correção parcial da prova de redação, como por exemplo somente um ou dois componentes ao invés de 5?\n",
    "\n",
    "As duas perguntas são resumidas em: será possível prever quem teria as melhores notas em todas as partes, somente tendo feito parte da prova?\n",
    "\n",
    "Para responder essa pergunta tentaremos modelar os dados de duas formas diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas para o projeto completo:\n",
    "\n",
    "- todo gráfico deve ter um título, labels e legendas que fazem sentido\n",
    "- configure um tamanho adequado para os gráficos\n",
    "- utilize as versões dos arquivos de dados disponíveis no github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: conferindo as versões utilizadas\n",
    "\n",
    "- Devemos usar pandas 0.24.0 ou mais recente\n",
    "- Devemos usar seaborn 0.9.0 ou mais recente\n",
    "- Devemos usar scipy 1.2.0 ou mais recente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"once\")\n",
    "\n",
    "!pip install pandas==\"0.24.0\" --quiet\n",
    "!pip install seaborn==\"0.9.0\" --quiet\n",
    "!pip install scipy==\"1.2.0\" --quiet\n",
    "!pip install yellowbrick==\"0.9.0\" --quiet\n",
    "!pip install numpy==\"1.16.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import yellowbrick\n",
    "import numpy as np\n",
    "\n",
    "print(\"Usando pandas %s\" % pd.__version__)\n",
    "print(\"Usando seaborn %s\" % sns.__version__)\n",
    "print(\"Usando scipy %s\" % scipy.__version__)\n",
    "print(\"Usando yellowbrick %s\" % yellowbrick.__version__)\n",
    "print(\"Usando numpy %s\" % np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos configurar o pandas para usar impressão de ponto flutuante com 3 casas decimais\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: carregue os dados\n",
    "\n",
    "- baixe os dados de 2017 em http://download.inep.gov.br/microdados/microdados_enem2017.zip\n",
    "- salve o arquivo `DADOS/MICRODADOS_ENEM_2017.CSV` em um diretório chamado `input/MICRODADOS_ENEM_2017.CSV`\n",
    "- leia esse arquivo com pandas na variável `enem`\n",
    "- nem sempre um arquivo separado por vírgulas (csv) vem separado por vírgulas, use o argumento `sep=';'` para indicar que o arquivo usou `;` como separador\n",
    "- nem sempre o arquivo vem com encoding UTF-8, use `encoding='iso-8859-1'` para indicar o encoding que foi utilizado no arquivo\n",
    "- não carregue todas as colunas. Existem muitos dados que não utilizaremos em nosso estudo. Para isso utilize o parâmetro `usecols=[\"NU_NOTA_CN\",\"NU_NOTA_CH\",\"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_COMP1\", \"NU_NOTA_COMP2\", \"NU_NOTA_COMP3\", \"NU_NOTA_COMP4\", \"NU_NOTA_COMP5\"]`\n",
    "- imprima os 5 primeiros elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# solução\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%d elementos e %d colunas\" % (enem.shape[0], enem.shape[1]))\n",
    "if(enem.shape[0] != 6731341):\n",
    "    print(\"ERRO! No conjunto de 2017 existem 6731341 dados\")\n",
    "if(enem.shape[1] != 9):\n",
    "    print(\"ERRO! Carregue somente 9 colunas relativas as notas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: abra o arquivo `DICIONARIO/Dicionário_Microdados_Enem_2017.xls`\n",
    "- explore quais são as colunas que possuem as notas das 4 avaliações e das 5 componentes analisadas em redação\n",
    "- crie uma lista chamada `todas_as_notas` com o nome dessas 9 colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem[todas_as_notas].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: alguns alunos e alunas não vieram na prova e possuem valores vazios.\n",
    "\n",
    "- Descarte todas as linhas que possuem valores inválidos\n",
    "- Sobrescreva a variável `enem`\n",
    "- Imprima as 5 primeiras notas de matemática (`MT`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: analise a nota total\n",
    "\n",
    "- a coluna `nota_total` deve ser a soma de todas as 9 notas\n",
    "- imprima as 5 primeiras notas totais\n",
    "- desenhe o histograma da nota total\n",
    "- descreva a `nota_total` em termos de média, mediana e desvio padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução e impressão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução histograma e descrição\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: extraia 1% dos dados para explorarmos\n",
    "\n",
    "- utilize o seed de aleatoriedade 745\n",
    "- use a função `sample` para extrair 1% dos dados em uma variável chamada `enem_eda`\n",
    "- plote o histograma de `enem_eda`\n",
    "- descreva a `nota_total` desse sample de 1%\n",
    "- a média, mediana e desvio padrão de nosso sample parecem representar o conjunto total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# solução sua função de sampling\n",
    "\n",
    "def eda_sample(enem):\n",
    "    # seed\n",
    "    # 1% de sample em enem_eda\n",
    "    print(\"Enem EDA sampling tem a distribuição\")\n",
    "    # descreva a nota_total\n",
    "    # plote o histograma da nota_total e mostre com plt.show()\n",
    "    return enem_eda\n",
    "\n",
    "enem_eda = eda_sample(enem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: analise a correlação entre as notas\n",
    "\n",
    "- inclua a `nota_total` a `todas_as_notas`\n",
    "- analise a correlação entre as variáveis contidas em todas as notas (uma tabela 10x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(correlacoes.shape != (10,10)):\n",
    "    print(\"A matriz de correlação deveria ser entre 10 notas, totalizando 10 linhas por 10 colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: analise a correlação da nota_total\n",
    "\n",
    "- extraia somente a linha relativa a `nota_total`\n",
    "- atribua essa tabela 1x10 a variável `correlacao_com_nota_total`\n",
    "- plote um gráfico de barras horizontais com o valor da correlação de cada nota com `nota_total`\n",
    "- o gráfico deve estar ordenado da correlação mais baixa no topo para a correlação mais alta no fim\n",
    "- use o estilo branco de gráficos do seaborn: `sns.set(style=\"white\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução: cálculo da tabela de correlação com todas as notas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correlacao_com_nota_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução gráfico\n",
    "\n",
    "def plota_correlacao(dados):\n",
    "    sns.set(style=\"white\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    corr = dados.corr()[\"nota_total\"].sort_values()\n",
    "    sns.barplot(y=corr.index, x=corr.values)\n",
    "    \n",
    "plota_correlacao(correlacao_com_nota_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: tente um primeiro modelo\n",
    "\n",
    "- Alguns estudiosos indicam que matemática e línguas formam a base para a educação\n",
    "- Com base nesse conhecimento prévio, utilize de `enem_eda` as colunas `NU_NOTA_MT` e `NU_NOTA_LC` e `nota_total`\n",
    "- Crie uma variável chamada `interesse` com esses dados\n",
    "- Crie uma função chamada `split` que recebe esses dados\n",
    "    - Ela usa o seed para números aleatórios do numpy 42367\n",
    "    - Ela faz um `train_test_split` com porcentagem de treino e teste padrão.\n",
    "    - Ela imprime o tamanho dos conjuntos resultantes de treino e teste\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução: definindo interesse e imprimindo os 5 primeiros elementos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução: a função de split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(dados):\n",
    "    # seed\n",
    "    # train_test_split\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Quebrando em treino (x,y) e teste (x,y)\", train_x.shape, train_y.shape,test_x.shape, test_y.shape)\n",
    "    print(\"Usando colunas %s como X\" % str(train_x.columns.values))\n",
    "    print(\"Desvio padrão do conjunto de testes\", test_y.std())\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código pronto\n",
    "\n",
    "train_x, test_x, train_y, test_y = split(interesse)\n",
    "if(train_x.shape[1]!=2):\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Erro! Você deveria possuir somente duas colunas em X\")\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: execute uma regressão linear\n",
    "\n",
    "- defina a função `roda_regressao_linear` que recebe os 4 conjuntos de dados de treino e teste (x e y)\n",
    "- treine um modelo `LinearRegression` do sklearn \n",
    "- calcule o R^2 score no conjunto de teste\n",
    "- calcule o mean squared error (`mse`) e o mean absolute error (`mae`) do conjunto de teste\n",
    "- imprima essas 3 métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução: função para executar a regressão linear\n",
    "\n",
    "def roda_regressao_linear(train_x, test_x, train_y, test_y):\n",
    "    \n",
    "    # crie o modelo, treine com os dados de treino\n",
    "    # calcule o r2_score com os dados de teste\n",
    "    # calcule a predição e os dois tipos de erros\n",
    "    \n",
    "    test_pred = model.predict(test_x)\n",
    "    print(\"*\" * 80)\n",
    "    print(\"r2 score\", r2_score)\n",
    "    print(\"mse\", mse)\n",
    "    print(\"mae\", mae)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "roda_regressao_linear(train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: analise o erro médio absoluto\n",
    "\n",
    "- compare o erro médio absoluto com o desvio padrão dos estudantes do conjunto de testes\n",
    "- o que você achou do erro encontrado com o uso desse modelo linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução\n",
    "\n",
    "    Coloque sua opinião aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando o erro\n",
    "\n",
    "Utilizando o módulo `yellowbrick` podemos rapidamente plotar os erros encontrados para cada estudante. No eixo X estará a `nota_total` real, enquanto no eixo Y a `nota_total` prevista pelo modelo. Quanto mais próxima da diagonal de identidade (x=y), mais correta a previsão do modelo.\n",
    "\n",
    "Quanto menor o mean absolute error menor, mais próximo da diagonal será o modelo linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "def visualiza_erros(train_x,train_y,test_x,test_y):\n",
    "    visualizer = PredictionError(LinearRegression())\n",
    "    visualizer.fit(train_x, train_y)\n",
    "    visualizer.score(test_x, test_y)\n",
    "    visualizer.poof()\n",
    "\n",
    "visualiza_erros(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando o erro\n",
    "\n",
    "Outra maneira importante de analisar o erro é ver a distribuição do resíduo, \"o quão errado\" nosso modelo está para os diversos valores previstos. No eixo X temos o valor previsto pelo modelo, enquanto no eixo Y o erro dessa previsão (os resíduos).\n",
    "\n",
    "Um modelo razoável que captura a relação entre as variáveis de X e a variável dependente y comete erros de maneira \"normal\", isto é, seus resíduos devem seguir uma distribuição normal, mostrando não haver uma tendência para erros maiores ou menores em determinadas situações.\n",
    "\n",
    "No gráfico a seguir você verá que a distribuição dos resíduos (gráfico da direita) se assemelham ao de uma normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "def visualiza_erros(train_x,train_y,test_x,test_y):\n",
    "    visualizer = PredictionError(LinearRegression())\n",
    "    visualizer.fit(train_x, train_y)\n",
    "    visualizer.score(test_x, test_y)\n",
    "    visualizer.poof()\n",
    "    \n",
    "    visualizer = ResidualsPlot(LinearRegression())\n",
    "    visualizer.fit(train_x, train_y)\n",
    "    visualizer.score(test_x, test_y)\n",
    "    visualizer.poof()\n",
    "\n",
    "visualiza_erros(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando combinações de features\n",
    "\n",
    "Ainda nessa fase de exploração escolhemos um conjunto de features (matemática e línguas) para tentar prever a nota final. Mas sabemos da correlação das variáveis de nota com a nota total que algumas possuem uma correlação maior do que outras.\n",
    "\n",
    "De maneira análoga ao código anterior execute o modelo linear para diversas combinações de notas que julgar pertinente.\n",
    "\n",
    "Para cada conjunto de notas que julgar pertinente:\n",
    "- escolha as colunas e crie a variável `interesse` com elas\n",
    "- invoque o `split` do `interesse`\n",
    "- aplique a `run_linear_regression`\n",
    "- aplique a `visualiza_erros`\n",
    "\n",
    "Dentre os modelos a testar, verifique alguns importantes:\n",
    "- com todas as 9 notas, o modelo é capaz de errar pouco? afinal a nota total é uma combinação linear de todas as 9 notas\n",
    "- com 8 notas, qual o erro mínimo?\n",
    "- com 1, 2 ou 3 notas que você julgar que faz sentido, quais erros encontra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "def regressao_completa_para(notas):\n",
    "    interesse = enem_eda[notas]\n",
    "    train_x, test_x, train_y, test_y = split(interesse)\n",
    "    model = roda_regressao_linear(train_x, test_x, train_y, test_y)\n",
    "    visualiza_erros(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 1: teste com todas as notas\n",
    "# crie várias células com as combinações que julgar necessárias invocando sempre `regressao_completa_para`\n",
    "# invoque ela com as notas que deseja analisar *E* a nota_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 2: teste outra combinação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 3: teste outra combinação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 4: teste outra combinação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 5: teste outra combinação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 6: teste outra combinação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução 7: teste outra combinação\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: tente um modelo específico\n",
    "\n",
    "- A prova de língua não envolve a criação de textos complexos, mas aborda a língua portuguesa\n",
    "- A prova de matemática junto coma de língua apresenta um modelo razoável\n",
    "- A prova de redação apresenta a oportunidade de criar textos complexos\n",
    "\n",
    "Juntando essas três informações tente o mesmo processo de 4 passos para o modelo linear com `NU_NOTA_LC`, `NU_NOTA_COMP3` e `NU_NOTA_MT`. Analise o erro médio absoluto, o R^2 e a distribuição dos erros comparados aos modelos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhemos as features, qual o estimador ideal?\n",
    "\n",
    "Vamos explorar mais ainda nosso conjunto de exploração. Vamos continuar com o conjunto de 3 notas, que seria uma possível conquista: somente com um componente de redação e 2 notas de provas seríamos capazes de prever razoavelmente a avaliação final de um aluno ou aluna.\n",
    "\n",
    "Apesar dos gráficos anteriores indicarem que o modelo linear tem sido razoável para nossos dados, vamos testar outros estimadores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Prepare diversos estimadores\n",
    "\n",
    "- Implemente a função `gera_regressores` que retorna uma lista de estimadores\n",
    "- Do sklearn coloque na lista:\n",
    "    - `LinearRegression`\n",
    "    - `Lasso`\n",
    "    - `Ridge`\n",
    "    - `DecisionTreeRegressor`\n",
    "    - `RandomForestRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def gera_regressores():\n",
    "    # gere os modelos em uma lista\n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste\n",
    "\n",
    "if(len(gera_regressores()) != 5):\n",
    "    print(\"Erro!!! São 5 regressores que queremos testar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pergunta: crie uma função que escolhe parte dos dados\n",
    "\n",
    "- implemente a função `escolhe_colunas`\n",
    "- ela recebe o conjunto de dados e as colunas a filtrar\n",
    "- escolha somente as colunas dos dados\n",
    "- chame o `split` para esses dados filtrados, separando em treino e teste, x e y\n",
    "- imprima o histograma de `train_y`\n",
    "- plote o gráfico com `plt.show()`\n",
    "- retorne `train_x, test_x, train_y, test_y` nessa ordem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n",
    "def escolhe_dados(dados, colunas):\n",
    "    # extraia as colunas\n",
    "    # faça o split\n",
    "    # plote o histograma de train_y\n",
    "    plt.show()\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: treine e gere as métricas\n",
    "\n",
    "- crie uma função para treinar e gerar as métricas de uma regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução:\n",
    "\n",
    "import time\n",
    "def treina_e_mede_regressor(modelo, train_x, test_x, train_y, test_y):\n",
    "    tic = time.time()\n",
    "    # treine seu modelo\n",
    "    tac = time.time()\n",
    "    tempo_de_treino = tac - tic\n",
    "\n",
    "    # calcule a previsão para test_x\n",
    "    # calcule o mse\n",
    "    # calcule o mae\n",
    "    print(\"Resultado\", modelo, mse, mae)\n",
    "\n",
    "    return mse, mae, tempo_de_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analisa_regressao(dados):\n",
    "    train_x, test_x, train_y, test_y = escolhe_dados(dados, [\"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_COMP3\", \"nota_total\"])\n",
    "    \n",
    "    resultados = []\n",
    "    for modelo in gera_regressores():\n",
    "        \n",
    "        # crie um pipeline chamado pipe usando StandardScaler() e o modelo\n",
    "        # use o make_pipeline ou crie um Pipeline\n",
    "        \n",
    "        mse, mae, tempo_de_treino = treina_e_mede_regressor(pipe, train_x, test_x, train_y, test_y)\n",
    "        \n",
    "        resultados.append([modelo, pipe, tempo_de_treino, mse, mae])\n",
    "        \n",
    "    resultados = pd.DataFrame(resultados, columns=[\"modelo\", \"pipe\", \"tempo_de_treino\", \"mse\", \"mae\"])\n",
    "    return test_x, test_y, resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y, notas = analisa_regressao(enem_eda)\n",
    "notas[[\"modelo\", \"mse\", \"mae\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado parcial\n",
    "\n",
    "Somente nos nossos dados de exploração fomos capazes de perceber que um modelo de regressão linear parece ser capaz de explicar a variável `nota_total` em função de três variáveis. Por mais que a rede neural possa ter se saído um pouco melhor na métrica de `mean absolute error`, o treino é longo mesmo para 5% dos dados, que ainda estamos explorando.\n",
    "\n",
    "Como uma regressão linear simples não possui hiper-parâmetros, nosso estudo de regressão vai parar por aqui. Possuímos indícios de que podemos usar um modelo de regressão em cima de 3 notas. Mas e no caso de identificarmos alunos e alunas para bolsa? Nesse caso não precisamos saber a nota final específica, mas sim se ela está no topo das pessoas que fizeram a prova. Isto é, o aluno ou aluna está ou não está no topo X% dos alunos?\n",
    "\n",
    "Ao invés de usarmos uma regressão, tentaremos usar uma classificação! É comum reduzir um problema de regressão em classificação através do \"encaixotamento\" (binning) dos valores. Por exemplo, se o topo 25% dos alunos possuem nota maior que 2600, então quem tem menos fica com 0 e quem tem mais fica com 1. Poderíamos fazer também uma classificação entre os menores 25% (0), o bolo do meio (1) e o topo 25% (2). Como nosso cliente deseja entender o topo dos alunos e alunas vamos para a abordagem de 0 e 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: As notas de treino\n",
    "\n",
    "- dado os últimos dados de teste gerados, gere um histograma da variável y (`nota_total` que é o `test_y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução: histograma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: criando as classes\n",
    "\n",
    "- Crie uma função chamada `top_p` que recebe uma série de dados e um p que indica o quantil, por padrão 0.75\n",
    "- A função devolve uma nova série\n",
    "- O resultado são 0s para  quem está abaixo do quantil, e 1s para quem está acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n",
    "def top_p(serie, p = 0.75):\n",
    "    # calcule o quantil p\n",
    "    print(\"quantile encontrado\", quant)\n",
    "    # defina y como sendo uma serie de 1s e 0s. 1 se o valor da serie for maior que o quantil, 0 se menor\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste do top 25%\n",
    "top_25 = top_p(pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]), p = 0.75).values\n",
    "if(not np.array_equal(top_25, [0,0,0,0,0,0,0,1,1,1])):\n",
    "    print(\"Não retornou o top 25% corretamente, deveria ser \", top_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste do top 10%\n",
    "\n",
    "top_10 = top_p(pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]), p = 0.90).values\n",
    "if(not np.array_equal(top_10, [0,0,0,0,0,0,0,0,0,1])):\n",
    "    print(\"Não retornou o top 10% corretamente, deveria ser\", top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando classes e features\n",
    "\n",
    "O `yellowbrick` permite visualizar o balanço de suas classes. O código a seguir vai conferir e permitir visualizar que separamos 25% dos alunos e alunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "y_top25 = top_p(test_y)\n",
    "y_top25.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "from yellowbrick.target import ClassBalance\n",
    "\n",
    "visualizer = ClassBalance(labels=[\"75%\", \"25%\"])\n",
    "visualizer.fit(y_top25)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para saber mais: agrupando\n",
    "\n",
    "O `yellowbrick` possui uma função para visualizar possíveis binnings. O código a seguir mostra 4 sugestões de pontos para agrupamento. Não usaremos a sugestão do yellowbrick pois no nosso caso o cliente já definiu que queria os X% do topo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "from yellowbrick.target import BalancedBinningReference\n",
    "\n",
    "visualizer = BalancedBinningReference()\n",
    "visualizer.fit(train_y)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O modelo completo para classificação\n",
    "\n",
    "Vamos passar agora pelo mesmo processo de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Prepare diversos estimadores\n",
    "\n",
    "- Implemente a função `gera_classificadores` que retorna uma lista de estimadores\n",
    "- Do sklearn coloque na lista:\n",
    "    - `DummyClassifier` com a estratégia `most_frequent` (mais frequente) que será nosso baseline\n",
    "    - `LogisticRegression`\n",
    "    - `RidgeClassifier`\n",
    "    - `DecisionTreeClassifier`\n",
    "    - `RandomForestClassifier(n_estimators=10)`\n",
    "    - `SVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n",
    "def gera_classificadores():\n",
    "    # defina seus modelos\n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "if(len(gera_classificadores()) != 6):\n",
    "    print(\"Erro!!! São 6 classificadores que queremos testar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: defina uma nova função de split, agora baseada nas classes\n",
    "\n",
    "- crie a função `split_classe` que recebe os `dados`\n",
    "- use `42367` como seed para o `numpy`\n",
    "- X são todas as colunas exceto a coluna `top_p`\n",
    "- y é a coluna `top_p`\n",
    "- chame `train_test_split`\n",
    "    - stratify é a coluna y\n",
    "- imprima os tamanhos dos conjuntos\n",
    "- imprima o número de colunas de X\n",
    "- imprima a média de test_y\n",
    "- retorne os conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classificacao(dados):\n",
    "    # faça o seed do numpy\n",
    "    # defina X como todas as colunas de `dados` exceto top_p\n",
    "    # defina y como somente a coluna top_p\n",
    "    # quebre em treino e teste, usando estratificação baseada em y\n",
    "\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Quebrando em treino (x,y) e teste (x,y)\", train_x.shape, train_y.shape,test_x.shape, test_y.shape)\n",
    "    print(\"Usando colunas %s como X\" % str(train_x.columns.values))\n",
    "    print(\"Média do conjunto de testes\", test_y.mean())\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando sua função de split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto: teste\n",
    "\n",
    "interesse = enem_eda[[\"nota_total\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_COMP3\"]]\n",
    "interesse['top_p'] = top_p(interesse['nota_total'])\n",
    "interesse = interesse[[\"top_p\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_COMP3\"]]\n",
    "\n",
    "train_x, test_x, train_y, test_y = split_classificacao(interesse)\n",
    "\n",
    "if(train_x.shape[1] != 3):\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Erro! Você deveria possuir somente três colunas em X\")\n",
    "    print(\"*\" * 80)\n",
    "\n",
    "if(test_y.mean() <= 0.24 or test_y.mean() >= 0.26):\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Erro! Você deveria capturar somente o top 25% e usar estratificação no split\")\n",
    "    print(\"*\" * 80)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: implemente o treino e o teste do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução:\n",
    "\n",
    "import time\n",
    "def treina_e_mede_classificador(pipe, nome, train_x, test_x, train_y, test_y):\n",
    "    tic = time.time()\n",
    "    # treine o pipeline\n",
    "    tac = time.time()\n",
    "    tempo_de_treino = tac - tic\n",
    "    # calcule a accuracy_score\n",
    "    print(\"Resultado\", nome, accuracy_score)\n",
    "\n",
    "    return accuracy_score, tempo_de_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta implemente a função de escolha de dados e split para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução:\n",
    "\n",
    "def escolhe_dados_para_classificacao(dados, colunas, p):\n",
    "    interesse = # selecione somente as colunas especificas de dados\n",
    "    nota_total = # somente a coluna nota_total\n",
    "    interesse['top_p'] = # defina quem está no top p\n",
    "\n",
    "    colunas.remove(\"nota_total\")\n",
    "    interesse = interesse[[*colunas, \"top_p\"]]\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = split_classificacao(interesse)\n",
    "    train_y.hist()\n",
    "    plt.show()\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando a escolha\n",
    "\n",
    "train_x, test_x, train_y, test_y = escolhe_dados_para_classificacao(enem_eda, [\"nota_total\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_COMP3\"], p=0.75)\n",
    "\n",
    "if(train_x.shape[1] != 3):\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Erro! Você deveria possuir somente três colunas em X\")\n",
    "    print(\"*\" * 80)\n",
    "\n",
    "if(test_y.mean() <= 0.24 or test_y.mean() >= 0.26):\n",
    "    print(\"*\" * 80)\n",
    "    print(\"Erro! Você deveria capturar somente o top 25% e usar estratificação no split\")\n",
    "    print(\"*\" * 80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "def analisa_classificacao(dados, p = 0.75):\n",
    "    \n",
    "    colunas = [\"nota_total\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_COMP3\"]\n",
    "    train_x, test_x, train_y, test_y = escolhe_dados_para_classificacao(dados, colunas, p=p)\n",
    "    \n",
    "    resultados = []\n",
    "    for modelo in gera_classificadores():\n",
    "        nome = type(modelo).__name__\n",
    "        pipe = make_pipeline(StandardScaler(), modelo)\n",
    "        accuracy_score, tempo_de_treino = treina_e_mede_classificador(pipe, nome, train_x, test_x, train_y, test_y)\n",
    "        resultados.append([nome, modelo, pipe, tempo_de_treino, accuracy_score])\n",
    "        \n",
    "    resultados = pd.DataFrame(resultados, columns=[\"tipo\", \"modelo\", \"pipe\", \"tempo_de_treino\", \"accuracy_score\"])\n",
    "    return test_x, test_y, resultados.set_index(\"tipo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: rode a analisa_classificacao\n",
    "\n",
    "- rode 6 vezes, cada uma em uma célular diferente, vamos ver o quão bem os modelos tentam prever o top X%\n",
    "- queremos o top 25% (quantil/p=0.75), top 20%, top 10%, top 5% e top 1%\n",
    "- queremos também rodar para as últimas 25% pessoas, isto é p=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# solução top 25%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução top 20%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# solução top 10%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução top 5%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução top 1%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução bottom 25%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o top 25%\n",
    "\n",
    "Dado o cenário de topo 25%, o DummyClassifier acertou 75% das vezes, errou 25%. O modelo que estamos criando conseguiria atingir no máximo esses 25% a mais de acerto (máximo de 100%). Se conferirmos que o modelo logístico acertou 93.7%, isso significa que 93.7% - 75% = 18.7%. Portanto do ganho máximo de 25% o modelo está acertando 18.7%, um total de 74.8% de ganho do potencial máximo de um modelo.\n",
    "\n",
    "Por mais que pareça pouco, esses 18.7% representam quase 3/4 de todo o ganho potencial que um modelo pode ter.\n",
    "\n",
    "Você pode fazer a mesma conta paa os outros ps, lembrando que essa não é uma métrica comum de se analisar. Na prática queremos entender agora como foi que o modelo errou. Ele errou os casos do bottom 75% e do top 25% igualmente? Ou errou mais em um dos dois casos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto: rodando para top 25%\n",
    "\n",
    "# rode a analisa_classificacao e armazene test_x, test_y e notas de 25%\n",
    "notas[[\"accuracy_score\", \"tempo_de_treino\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando a matriz de confusão\n",
    "\n",
    "Vamos ver quantas vezes os dois principais modelos (Regressão logística e SVC) acertam e erram. Para isso plotaremos a matriz de confusão (código pronto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    \n",
    "    classes = ['Não topo 25%','Topo 25%']\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Matriz de confusão normalizada')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f') + '%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Classe real')\n",
    "    plt.xlabel('Classe predita')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_confusion_for(test_x, test_y, model):\n",
    "    pred_y = model.predict(test_x)\n",
    "    print(\"Acurácia do modelo em teste\", model.score(test_x, test_y))\n",
    "    cnf_matrix = confusion_matrix(test_y, pred_y)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "print_confusion_for(test_x, test_y, notas.loc['LogisticRegression']['pipe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto\n",
    "\n",
    "print_confusion_for(test_x, test_y, notas.loc['SVC']['pipe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos validar?\n",
    "\n",
    "Como o algoritmo de regressão logística simples obteve resultados bons, assim como o de SVC, podemos analisar a matriz de confusão para fazer a escolha. Repare que a regressão logística apresenta maior taxa de acerto no topo 25%, portanto vamos mantê-la.\n",
    "\n",
    "Como escolhemos uma regressão logística, não possuimos um hiperparâmetro para otimizar, e vamos direto validar o modelo que treinamos. Primeiro separaremos os dados para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código pronto: separando os dados não usados para treino (que foram os usados em eda)\n",
    "\n",
    "usados_no_eda = enem_eda.index\n",
    "a_usar = ~enem.index.isin(usados_no_eda)\n",
    "enem_validacao = enem[a_usar]\n",
    "print(\"Para otimização temos %d elementos\" % len(enem_validacao))\n",
    "del(a_usar)\n",
    "del(usados_no_eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: separe os dados adequadamente de validação\n",
    "\n",
    "- implemente a função `separa_dados_de_classificacao_para_validacao`\n",
    "- X são todas as 3 colunas originais da análise\n",
    "- Y é o `top_p` indicando se aquele aluno ou aluna está no top 25% baseado em sua `nota_total`\n",
    "- imprima a média do conjunto Y\n",
    "- retorne `X, y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_dados_de_classificacao_para_validacao(dados):\n",
    "    X = # selecione as 3 colunas\n",
    "    y = # calcule o top 25% como 1 o bottom 75% como 0\n",
    "    print(\"Média da validação\", y.mean())\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: defina uma função de validação cruzada de um modelo de classificação\n",
    "\n",
    "- implemente a função `treina_e_valida_modelo_de_classificacao` que recebe os dados e o modelo\n",
    "- separe os dados em X e y usando `separa_dados_de_classificacao_para_validacao`\n",
    "- rode um cross_val_score com o pipe, 5 folds de validação cruzada estratificada\n",
    "- imprima a acurácia encontrada na validação cruzada\n",
    "- faça o treinamento do modelo\n",
    "- imprima a matriz de confusão do `modelo` para `X` e `y`\n",
    "\n",
    "Dicas:\n",
    "- na validação cruzada, utilize o parâmetro `verbose=1` pois o processo pode levar alguns minutos\n",
    "- na validação cruzada, utilize o parâmetro `n_jobs=-1` para usar todos os processadores possíveis de seu computador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def treina_e_valida_modelo_de_classificacao(dados, modelo):\n",
    "    # calcule X e y usando a função anterior\n",
    "    \n",
    "    scores = # calcule o cross_val_score\n",
    "    mean = scores.mean()\n",
    "    std = scores.std()\n",
    "    print(\"Acurácia entre [%.2f,%.2f]\" % (100*mean - 2*std, 100*mean + 2*std))\n",
    "    \n",
    "    modelo.fit(X, y)\n",
    "    print_confusion_for(X, y, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logistica = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "treina_e_valida_modelo_de_classificacao(enem_validacao, pipeline_logistica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation e a matriz de confusão\n",
    "\n",
    "Os dois resultados vão dar uma ideia do quão bom seu modelo será no mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lembrei de uma coisinha...\n",
    "\n",
    "É **muito** comum no mundo real chegarmos em um resultado pior que nosso baseline. Nesses dados conseguimos um modelo razoável, mas mesmo assim também é **bem** comum, no final do processo de modelagem, lembrar de um outro tipo de modelo de base que poderíamos usar de comparação. Qual heurística simples poderia nos dizer quem vai estar nos top 25%? Repara que essa pergunta deve ser feita **antes** de se começar o projeto. Mas mesmo assim é muito comum somente próximo ao fim do projeto, agora entendendo melhor nosso conjunto de dados, chegar a ideias de heurísticas simples e poderosas que poderiam ser melhores que um modelo complexo. Infelizmente isso também pode acontecer com uma frequencia razoável. Temos que entender que faz parte: testamos heurísticas antes (como o DummyClassifier) e em qualquer momento que vierem a cabeça.\n",
    "\n",
    "Vamos então testar uma delas?\n",
    "\n",
    "Se soment sabemos as 3 notas de um aluno ou aluna, será que quem está no top 25% dessas 3 notas serão as pessoas que estarão no top 25% de todas as notas? Parece ser algo razoável de se imaginar como verdadeiro. Vamos então criar o **nosso estimador**! É normal \"suar frio\" nesse instante, será que a heurística - que parece fazer sentido - será melhor que o modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Implementando nosso estimador\n",
    "\n",
    "Vamos implementar uma classe com diversas funções que todos os estimadores devem possuir. Ao treinar nosso estimador ele olha todos os alunos de treino e calcula a nota que separa o top 25%. Ao validar ele usa essa nota: se o aluno ou aluna tem uma nota maior que a nota de corte, é top 25% (1), caso contrário não é (0).\n",
    "\n",
    "- Implemente a função `fit`. Ela recebe em X as 3 colunas que desejamos somar e deve calcular qual é o quantil de top 25%\n",
    "- Implemente a função `predict`. Ela recebe X com as 3 colunas, calcula a soma delas e verifica quem está acima do quantil. Quem está acima é classificada como 1, quem está abaixo como 0\n",
    "- Implemente a função `score`. Ela calcula a acurácia usando a função `accuracy_score` e as predições que o próprio estimador fez\n",
    "- A função `get_params` não devolve nada uma vez que nosso estimador não possue paramêtros a serem otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solução: implemente o código que falta\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class HeuristicaTop25:\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        if(X.shape[1] != 3):\n",
    "            print(\"Erro!!! Estávamos esperando 3 colunas!\")\n",
    "            \n",
    "        parcial = # some **por coluna**. a função sum recebe um parâmetro para somar por coluna, não linha\n",
    "        self.top_25_quantile = pd.Series(parcial).quantile(0.75)\n",
    "        print(\"top 25 quantile é %.2f\" % self.top_25_quantile)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y = None):\n",
    "        parcial = # some por coluna\n",
    "        y_pred_true_false = # compare a soma parcial com o self.top25_quantile\n",
    "        y_pred = # 1 se for maior ou igual, 0 caso contrário\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y = None):\n",
    "        return accuracy_score(y, self.predict(X, y))\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "treina_e_valida_modelo_de_classificacao(enem_validacao, HeuristicaTop25())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Compare os resultados  da acurácia e da matriz de confusão entre (a) heurística final com (b) o DummyClassifier e (c) a LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solução\n",
    "\n",
    "    Sua solução aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Sugira uma outra heurística que poderia ser usada para tentar detectar facilmente o top 25%, sem a necessidade de um modelo complexo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solução\n",
    "\n",
    "    Sua solução aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta: Se uma faculdade oferecer bolsa somente para quem o modelo julgar estar no top 25% o que acontece quando ele julga errôneamente que alguém não está no top 25%? E se julgar errôneamente que está no top 25%?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solução\n",
    "\n",
    "    Sua solução aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para saber mais\n",
    "\n",
    "Essa seção serve para instigar sua curiosidade em possíveis caminhos que queira ler e se aprofundar, todos ligados ao projeto atual. Nenhum deles é obrigatório para o projeto em si.\n",
    "\n",
    "### TRI \n",
    "\n",
    "Na prática a prova do Enem já usa métodos estatísticos para entender as dificuldades de suas questões e balanceá-las de diversas maneiras. A Teoria de Resposta ao Item (IRT em inglês) é uma das abordagens usadas para analisar e adaptar questões e provas. No Brasil diversas empresas e startups usam a tecnologia para entender as dificuldades e facilidades que pessoas possuem, com o objetivo de otimizar o estudo das mesmas.\n",
    "\n",
    "### E no ano seguinte?\n",
    "\n",
    "Devido ao TRI podemos esperar uma certa uniformidade entre provas aplicadas em anos diferentes. Mas fica a questão: estamos treinando agora nosso modelo com X% dos alunos que fizeram a prova em um ano X, portanto precisaríamos que X% dos alunos fizessem a prova completa para termos um modelo capaz de julgar somente a partir das provas parciais: não removemos a necessidade de criação da prova. Imaginando que grande parte do custo está na distribuição e correção manual da redação, existe muita margem para otimização.\n",
    "\n",
    "Uma outra abordagem seria treinar o modelo nos dados de um ano anterior a X e ver se o modelo se comporta bem para todos os anos posteriores. Repare como a definição do processo de separação dos dados de treino (por %? por ano?) e de validação faz muita diferença em entender como podemos usar o modelo no mundo real.\n",
    "\n",
    "### 25%?\n",
    "\n",
    "Nossa heurística envolveu usar o top 25%, mas poderíamos testar com os top 30% das notas parciais se seriam os top 25% das notas totais. Estaríamos errando mais para um lado do que para o outro, e isso pode ser aceitável por nosso cliente. Poderíamos continuar com a modelagem, criando um hiper parâmetro em nosso modelo e tentando otimizá-lo, por exemplo, a medida que conversamos com a empresa cliente\n",
    "\n",
    "### Redes neurais\n",
    "\n",
    "Neste projeto não usamos redes neurais (TensorFlow, Keras, Pytorch etc) mas é outro tipo de classificador, assim como AdaBoost e outros que poderiam ser utilizados. Como o conjunto de dados é bem grande e o relacionamento entre as notas é linear (sabemos que a nota total é a soma das notas parciais, mas não sabemos a relação entre as notas que não usamos), os modelos mais simples foram capazes de pegar boa parte do padrão encontrando nos resultados finais.\n",
    "\n",
    "\n",
    "### Classes balanceadas\n",
    "\n",
    "Se usamos 75% e 25% existe um desbalanceamento das classes e isso bagunça nossas métricas e análises. O mesmo ocorreria com 3 ou mais classes distintas. Existem diversas abordagens para tentar corrigir isso. Uma delas é simplesmente remover parte dos dados da classe que está aparecendo \"demais\". Isto é, dos 75%, joga uma parte aleatória fora (ou usa outros métodos para criar/remover samples). O código a seguir é um exemplo de como balancear através de jogar fora dados aleatoriamente. Dado os dados já com a coluna `top_p` ele vai balancear para 50% 50% as classes:\n",
    "\n",
    "```\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def random_under_sampler(dados):\n",
    "    X = dados.drop('top_p', axis=1)\n",
    "    y = dados['top_p']\n",
    "    X_under, y_under = RandomUnderSampler(random_state=0).fit_resample(X, y)\n",
    "    X_under = pd.DataFrame(X_under, columns=X.columns)\n",
    "    X_under['top_p'] = y_under\n",
    "    return X_under\n",
    "```\n",
    "\n",
    "Teríamos que levar em consideração que o DummyClassifier passaria a acertar agora somente 50% dos casos, pois as duas classes aparecem proporcionalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parabéns, você concluiu o projeto da Alura!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
